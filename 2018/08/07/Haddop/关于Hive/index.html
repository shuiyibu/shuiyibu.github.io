<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="hadoop,Hive,">





  <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">






<meta name="description" content="./hive -hiveconf hive.root.logger=DEBUG,console准备通过控制台输出来定位出错位置，没想到这样设置后，运行程序就成功了。自己比较莫名其妙。总之还是要养成常看错误日志解决问题。 安装Hive1234567891011121314151617181920212223242526[dylanlang@dylan20 ~/learning/hadoop]$ m">
<meta name="keywords" content="hadoop,Hive">
<meta property="og:type" content="article">
<meta property="og:title" content="关于Hive">
<meta property="og:url" content="http://yoursite.com/2018/08/07/Haddop/关于Hive/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="./hive -hiveconf hive.root.logger=DEBUG,console准备通过控制台输出来定位出错位置，没想到这样设置后，运行程序就成功了。自己比较莫名其妙。总之还是要养成常看错误日志解决问题。 安装Hive1234567891011121314151617181920212223242526[dylanlang@dylan20 ~/learning/hadoop]$ m">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-08-08T11:55:38.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="关于Hive">
<meta name="twitter:description" content="./hive -hiveconf hive.root.logger=DEBUG,console准备通过控制台输出来定位出错位置，没想到这样设置后，运行程序就成功了。自己比较莫名其妙。总之还是要养成常看错误日志解决问题。 安装Hive1234567891011121314151617181920212223242526[dylanlang@dylan20 ~/learning/hadoop]$ m">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/08/07/Haddop/关于Hive/">





  <title>关于Hive | Hexo</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4d5b541690a836307558f5f13157a238";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/07/Haddop/关于Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dylan Lang">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">关于Hive</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-07T15:36:50+08:00">
                2018-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/07/Haddop/关于Hive/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/08/07/Haddop/关于Hive/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <a id="more"></a>
<p>./hive -hiveconf hive.root.logger=DEBUG,console<br>准备通过控制台输出来定位出错位置，没想到这样设置后，运行程序就成功了。自己比较莫名其妙。<br>总之还是要养成常看错误日志解决问题。</p>
<h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop]$ mkdir hive</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop]$ cd hive/</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ wget https://archive.apache.org/dist/hive/hive-<span class="number">0.13</span>.<span class="number">1</span>/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ ll</span><br><span class="line">总用量 <span class="number">52976</span></span><br><span class="line">-rw-rw-r--. <span class="number">1</span> dylanlang dylanlang <span class="number">54246778</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ tar zxf apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin.tar.gz</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ cd apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin/</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ ll</span><br><span class="line">总用量 <span class="number">284</span></span><br><span class="line">drwxrwxr-x. <span class="number">3</span> dylanlang dylanlang    <span class="number">119</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> bin</span><br><span class="line">drwxrwxr-x. <span class="number">2</span> dylanlang dylanlang    <span class="number">148</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> conf</span><br><span class="line">drwxrwxr-x. <span class="number">4</span> dylanlang dylanlang     <span class="number">34</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> examples</span><br><span class="line">drwxrwxr-x. <span class="number">7</span> dylanlang dylanlang     <span class="number">68</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> hcatalog</span><br><span class="line">drwxrwxr-x. <span class="number">4</span> dylanlang dylanlang   <span class="number">4096</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> lib</span><br><span class="line">-rw-rw-r--. <span class="number">1</span> dylanlang dylanlang  <span class="number">23828</span> <span class="number">1</span>月  <span class="number">30</span> <span class="number">2014</span> LICENSE</span><br><span class="line">-rw-rw-r--. <span class="number">1</span> dylanlang dylanlang    <span class="number">277</span> <span class="number">5</span>月  <span class="number">13</span> <span class="number">2014</span> NOTICE</span><br><span class="line">-rw-rw-r--. <span class="number">1</span> dylanlang dylanlang   <span class="number">3838</span> <span class="number">5</span>月  <span class="number">23</span> <span class="number">2014</span> README.txt</span><br><span class="line">-rw-rw-r--. <span class="number">1</span> dylanlang dylanlang <span class="number">253839</span> <span class="number">6</span>月   <span class="number">3</span> <span class="number">2014</span> RELEASE_NOTES.txt</span><br><span class="line">drwxrwxr-x. <span class="number">3</span> dylanlang dylanlang     <span class="number">23</span> <span class="number">8</span>月   <span class="number">7</span> <span class="number">15</span>:<span class="number">46</span> scripts</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ pwd</span><br><span class="line">/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ vi ~/.bashrc</span><br><span class="line"> export HIVE_HOME=/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin</span><br><span class="line"> export PATH=<span class="variable">$PATH:</span><span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ . ~/.bashrc</span><br></pre></td></tr></table></figure>
<h2 id="启动Hive"><a href="#启动Hive" class="headerlink" title="启动Hive"></a>启动Hive</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ hive</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin/lib/hive-common-<span class="number">0.13</span>.<span class="number">1</span>.jar!/hive-log4j.properties</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.603</span> seconds</span><br><span class="line">hive&gt; <span class="keyword">exit</span></span><br><span class="line">    &gt; ;</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin]$ cd ..</span><br><span class="line"></span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ hive -e <span class="string">"create table dummy (value string); load data local inpath '/tmp/dummy.txt' overwrite into table dummy"</span></span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin/lib/hive-common-<span class="number">0.13</span>.<span class="number">1</span>.jar!/hive-log4j.properties</span><br><span class="line">FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:Got exception: java.net.ConnectException Call From dylan20/<span class="number">192.168</span>.<span class="number">65.20</span> to localhost:<span class="number">8020</span> failed on connection exception: java.net.ConnectException: 拒绝连接; <span class="keyword">For</span> more details see:  http://wiki.apache.org/hadoop/ConnectionRefused)</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ jps -l</span><br><span class="line"><span class="number">16459</span> sun.tools.jps.Jps</span><br></pre></td></tr></table></figure>
<p>遇到该问题是因为没有启动hadoop<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ hdfs  namenode -format</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ start-dfs.sh</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ hive -e <span class="string">"create table dummy (value string); load data local inpath '/tmp/dummy.txt' overwrite into table dummy"</span></span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin/lib/hive-common-<span class="number">0.13</span>.<span class="number">1</span>.jar!/hive-log4j.properties</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">2.748</span> seconds</span><br><span class="line">Copying <span class="keyword">data</span> from file:/tmp/dummy.txt</span><br><span class="line">Copying file: file:/tmp/dummy.txt</span><br><span class="line">Loading <span class="keyword">data</span> to table default.dummy</span><br><span class="line">rmr: DEPRECATED: Please use <span class="string">'rm -r'</span> instead.</span><br><span class="line">Deleted hdfs://localhost/user/hive/warehouse/dummy</span><br><span class="line">Table default.dummy stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">2</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">2.232</span> seconds</span><br></pre></td></tr></table></figure></p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive]$ hive</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/dylanlang/learning/hadoop/hive/apache-hive-<span class="number">0.13</span>.<span class="number">1</span>-bin/lib/hive-common-<span class="number">0.13</span>.<span class="number">1</span>.jar!/hive-log4j.properties</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; create table records (year string, temperature int, quality int) row format delimited fields terminated by <span class="string">'\t'</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">1.555</span> seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt'</span> overwrite into table records;</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt</span><br><span class="line">Loading <span class="keyword">data</span> to table default.records</span><br><span class="line">rmr: DEPRECATED: Please use <span class="string">'rm -r'</span> instead.</span><br><span class="line">Deleted hdfs://localhost/user/hive/warehouse/records</span><br><span class="line">Table default.records stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">56</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">1.316</span> seconds</span><br><span class="line">hive&gt;</span><br><span class="line"></span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/input/ncdc/micro-tab]$ hadoop fs -ls /user/hive/warehouse/records</span><br><span class="line">Found <span class="number">1</span> items</span><br><span class="line">-rw-r--r--   <span class="number">1</span> dylanlang supergroup         <span class="number">56</span> <span class="number">2018</span>-<span class="number">08</span>-<span class="number">07</span> <span class="number">16</span>:<span class="number">17</span> /user/hive/warehouse/records/sample.txt</span><br><span class="line">hive&gt; select year, max(temperature) from records where temperature !=<span class="number">9999</span> and quality <span class="keyword">in</span> (<span class="number">0</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">9</span>) group by year;</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks not specified. Estimated from input <span class="keyword">data</span> size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">java.io.IOException: Cannot initialize Cluster. Please check your configuration <span class="keyword">for</span> mapreduce.framework.name and the correspond server addresses.</span><br><span class="line">        at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:<span class="number">120</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:<span class="number">82</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Cluster.&lt;init&gt;(Cluster.java:<span class="number">75</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.init(JobClient.java:<span class="number">470</span>)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.&lt;init&gt;(JobClient.java:<span class="number">449</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:<span class="number">397</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:<span class="number">136</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:<span class="number">153</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:<span class="number">85</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:<span class="number">1503</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:<span class="number">1270</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:<span class="number">1088</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:<span class="number">911</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:<span class="number">901</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:<span class="number">268</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:<span class="number">220</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:<span class="number">423</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:<span class="number">792</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:<span class="number">686</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:<span class="number">625</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">212</span>)</span><br><span class="line">Job Submission failed with exception <span class="string">'java.io.IOException(Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.)'</span></span><br><span class="line">FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</span><br></pre></td></tr></table></figure>
<h2 id="运行hive"><a href="#运行hive" class="headerlink" title="运行hive"></a>运行hive</h2><ul>
<li>多用户共享hive目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-0.13.1-bin/conf]$ hadoop fs -mkdir /tmp</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">mkdir: `/tmp&apos;: File exists</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-0.13.1-bin/conf]$ hadoop fs -chmod a+w /tmp</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-0.13.1-bin/conf]$ hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-0.13.1-bin/conf]$ hadoop fs -chmod a+w /user/hive/warehouse</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/apache-hive-0.13.1-bin/conf]$</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="分区和桶"><a href="#分区和桶" class="headerlink" title="分区和桶"></a>分区和桶</h2><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create table logs(ts bigint, line string) partitioned by(dt string, country string);</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.339</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file1'</span> into table logs partition(dt=<span class="string">'2001-01-01'</span>, country=<span class="string">'GB'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file1</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file1</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=GB)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=GB&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">12</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.983</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file2'</span> into table logs partition(dt=<span class="string">'2001-01-01'</span>, country=<span class="string">'GB'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file2</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file2</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=GB)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=GB&#125; stats: [numFiles=<span class="number">2</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">24</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.557</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file3'</span> into table logs partition(dt=<span class="string">'2001-01-01'</span>, country=<span class="string">'US'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file3</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file3</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=US)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">01</span>, country=US&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">12</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.408</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file4'</span> into table logs partition(dt=<span class="string">'2001-01-02'</span>, country=<span class="string">'GB'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file4</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file4</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=GB)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=GB&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">12</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.437</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file5'</span> into table logs partition(dt=<span class="string">'2001-01-02'</span>, country=<span class="string">'US'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file5</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file5</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=US)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=US&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">12</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.35</span> seconds</span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/hive/partitions/file6'</span> into table logs partition(dt=<span class="string">'2001-01-02'</span>, country=<span class="string">'US'</span>);</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/hive/partitions/file6</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/hive/partitions/file6</span><br><span class="line">Loading <span class="keyword">data</span> to table default.logs partition (dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=US)</span><br><span class="line">Partition default.logs&#123;dt=<span class="number">2001</span>-<span class="number">01</span>-<span class="number">02</span>, country=US&#125; stats: [numFiles=<span class="number">2</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">24</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.501</span> seconds</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~]$ hadoop fs -ls /user/hive/warehouse/logs</span><br><span class="line">2018-08-08 15:23:05,169 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - dylanlang supergroup          0 2018-08-08 15:21 /user/hive/warehouse/logs/dt=2001-01-01</span><br><span class="line">drwxr-xr-x   - dylanlang supergroup          0 2018-08-08 15:22 /user/hive/warehouse/logs/dt=2001-01-02</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; SHOW partitions logs;</span><br><span class="line">OK</span><br><span class="line">dt=2001-01-01/country=GB</span><br><span class="line">dt=2001-01-01/country=US</span><br><span class="line">dt=2001-01-02/country=GB</span><br><span class="line">dt=2001-01-02/country=US</span><br><span class="line">Time taken: 0.133 seconds, Fetched: 4 row(s)</span><br><span class="line">hive&gt; select ts,dt ,line from logs where country=&apos;GB&apos;;</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks is set to 0 since there&apos;s no reduce operator</span><br><span class="line">2018-08-08 15:34:28,421 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">2018-08-08 15:34:28,687 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_15-34-23_178_303197739844509199-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line">2018-08-08 15:34:28,692 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_15-34-23_178_303197739844509199-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">Execution log at: /tmp/dylanlang/dylanlang_20180808153434_e12519d7-11d6-4a70-a785-1cf3e9ac5e73.log</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">Hadoop job information for null: number of mappers: 0; number of reducers: 0</span><br><span class="line">2018-08-08 15:34:32,320 null map = 100%,  reduce = 0%</span><br><span class="line">Ended Job = job_local1732476934_0001</span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">OK</span><br><span class="line">1       2001-01-01      Log line 1</span><br><span class="line">2       2001-01-01      Log line 2</span><br><span class="line">4       2001-01-02      Log line 4</span><br><span class="line">Time taken: 10.067 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure>
<h3 id="桶"><a href="#桶" class="headerlink" title="桶"></a>桶</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.enforce.sorting=true;</span><br><span class="line">hive&gt; set hive.enforce.bucketing = true;</span><br><span class="line"></span><br><span class="line">hive&gt; create table bucketed_user (id int, name string) clustered by (id) sorted by (id asc)  into <span class="number">4</span> buckets;</span><br><span class="line"></span><br><span class="line">hive&gt; insert into table bucketed_user select * from (select stack (<span class="number">4</span>, <span class="number">0</span>, <span class="string">'Nat'</span>, <span class="number">2</span>, <span class="string">'Joe'</span>, <span class="number">3</span>, <span class="string">'Kay'</span>, <span class="number">4</span>, <span class="string">'Ann'</span> ))s;</span><br><span class="line"></span><br><span class="line">hive&gt; select * from bucketed_user;</span><br><span class="line">OK</span><br><span class="line"><span class="number">0</span>       Nat</span><br><span class="line"><span class="number">2</span>       Joe</span><br><span class="line"><span class="number">3</span>       Kay</span><br><span class="line"><span class="number">4</span>       Ann</span><br><span class="line">Time taken: <span class="number">0.035</span> seconds, Fetched: <span class="number">4</span> row(s)</span><br><span class="line"></span><br><span class="line">hive&gt; dfs -ls /user/hive/warehouse/bucketed_user;</span><br><span class="line">Found <span class="number">4</span> items</span><br><span class="line">-rw-r--r--   <span class="number">1</span> dylanlang supergroup         <span class="number">12</span> <span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">16</span>:<span class="number">13</span> /user/hive/warehouse/bucketed_user/<span class="number">000000</span>_0</span><br><span class="line">-rw-r--r--   <span class="number">1</span> dylanlang supergroup          <span class="number">0</span> <span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">16</span>:<span class="number">13</span> /user/hive/warehouse/bucketed_user/<span class="number">000001</span>_0</span><br><span class="line">-rw-r--r--   <span class="number">1</span> dylanlang supergroup          <span class="number">6</span> <span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">16</span>:<span class="number">13</span> /user/hive/warehouse/bucketed_user/<span class="number">000002</span>_0</span><br><span class="line">-rw-r--r--   <span class="number">1</span> dylanlang supergroup          <span class="number">6</span> <span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">16</span>:<span class="number">13</span> /user/hive/warehouse/bucketed_user/<span class="number">000003</span>_0</span><br><span class="line"></span><br><span class="line">hive&gt; dfs -cat /user/hive/warehouse/bucketed_user/<span class="number">000000</span>_0;</span><br><span class="line"><span class="number">4</span>Ann</span><br><span class="line"><span class="number">0</span>Nat</span><br><span class="line">hive&gt;</span><br><span class="line"></span><br><span class="line">hive&gt; select * from bucketed_user tablesample(bucket <span class="number">1</span> out of <span class="number">2</span> on id);</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">2018-08-08 16:17:22,353 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span></span><br><span class="line"><span class="string">2018-08-08 16:17:22,583 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_16-17-20_009_2360340951844875956-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span></span><br><span class="line"><span class="string">2018-08-08 16:17:22,594 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_16-17-20_009_2360340951844875956-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span></span><br><span class="line"><span class="string">Execution log at: /tmp/dylanlang/dylanlang_20180808161717_b7129a4c-667c-4116-a71d-2ef92669dabd.log</span></span><br><span class="line"><span class="string">Job running in-process (local Hadoop)</span></span><br><span class="line"><span class="string">Hadoop job information for null: number of mappers: 0; number of reducers: 0</span></span><br><span class="line"><span class="string">2018-08-08 16:17:25,929 null map = 100%,  reduce = 0%</span></span><br><span class="line"><span class="string">Ended Job = job_local275009289_0001</span></span><br><span class="line"><span class="string">Execution completed successfully</span></span><br><span class="line"><span class="string">MapredLocal task succeeded</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">4       Ann</span></span><br><span class="line"><span class="string">0       Nat</span></span><br><span class="line"><span class="string">2       Joe</span></span><br><span class="line"><span class="string">Time taken: 6.285 seconds, Fetched: 3 row(s)</span></span><br></pre></td></tr></table></figure>
<h2 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; describe  records;</span><br><span class="line">OK</span><br><span class="line">year                    string</span><br><span class="line">temperature             int</span><br><span class="line">quality                 int</span><br><span class="line">Time taken: <span class="number">0.17</span> seconds, Fetched: <span class="number">3</span> row(s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; select * from records;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1950</span>    <span class="number">0</span>       <span class="number">1</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">22</span>      <span class="number">1</span></span><br><span class="line"><span class="number">1950</span>    -<span class="number">11</span>     <span class="number">1</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">111</span>     <span class="number">1</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">78</span>      <span class="number">1</span></span><br><span class="line">Time taken: <span class="number">0.019</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br><span class="line">hive&gt;</span><br><span class="line">CREATE TABLE records2 (station STRING, year STRING, temperature INT, quality INT)</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">  FIELDS TERMINATED BY <span class="string">'\t'</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.047</span> seconds</span><br><span class="line"></span><br><span class="line">hive&gt; select * from records2;</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.044</span> seconds</span><br><span class="line"></span><br><span class="line">hive&gt; load <span class="keyword">data</span> local inpath <span class="string">'/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt'</span> overwrite into table records2;</span><br><span class="line">Copying <span class="keyword">data</span> from file:/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt</span><br><span class="line">Copying file: file:/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt</span><br><span class="line">Loading <span class="keyword">data</span> to table default.records2</span><br><span class="line">rmr: DEPRECATED: Please use <span class="string">'rm -r'</span> instead.</span><br><span class="line">Deleted hdfs://localhost:<span class="number">9000</span>/user/hive/warehouse/records2</span><br><span class="line">Table default.records2 stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">56</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.338</span> seconds</span><br><span class="line"></span><br><span class="line">hive&gt; select * from records2;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1950</span>    <span class="number">0</span>       <span class="number">1</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">22</span>      <span class="number">1</span></span><br><span class="line"><span class="number">1950</span>    -<span class="number">11</span>     <span class="number">1</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">111</span>     <span class="number">1</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">78</span>      <span class="number">1</span></span><br><span class="line">Time taken: <span class="number">0.021</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<h3 id="排序和聚集"><a href="#排序和聚集" class="headerlink" title="排序和聚集"></a>排序和聚集</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">hive&gt; from records2</span><br><span class="line">    &gt; select year, temperature</span><br><span class="line">    &gt; distribute by year</span><br><span class="line">    &gt; sort by year asc, temperature desc;</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks not specified. Estimated from input <span class="keyword">data</span> size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">20</span>:<span class="number">36</span>,<span class="number">621</span> WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(<span class="number">62</span>)) - Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">20</span>:<span class="number">36</span>,<span class="number">831</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">20</span>-<span class="number">34</span>_259_7832853047248417517-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">20</span>:<span class="number">36</span>,<span class="number">884</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">20</span>-<span class="number">34</span>_259_7832853047248417517-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">Execution log at: /tmp/dylanlang/dylanlang_20180808172020_52d5b2c7-<span class="number">0010</span>-<span class="number">4</span>e13-<span class="number">8535</span>-f38936965a54.log</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">Hadoop job information <span class="keyword">for</span> null: number of mappers: <span class="number">0</span>; number of reducers: <span class="number">0</span></span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">20</span>:<span class="number">40</span>,<span class="number">548</span> null map = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">20</span>:<span class="number">41</span>,<span class="number">575</span> null map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</span><br><span class="line">Ended Job = job_local2079529597_0001</span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">OK</span><br><span class="line"><span class="number">1949</span>    <span class="number">111</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">78</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">22</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">0</span></span><br><span class="line"><span class="number">1950</span>    -<span class="number">11</span></span><br><span class="line">Time taken: <span class="number">7.73</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br><span class="line"></span><br><span class="line">hive&gt; from records2 select year, temperature cluster by year;</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks not specified. Estimated from input <span class="keyword">data</span> size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">24</span>:<span class="number">08</span>,<span class="number">559</span> WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(<span class="number">62</span>)) - Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">24</span>:<span class="number">08</span>,<span class="number">790</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">24</span>-<span class="number">06</span>_373_2095203710382832258-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">24</span>:<span class="number">08</span>,<span class="number">812</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">24</span>-<span class="number">06</span>_373_2095203710382832258-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">Execution log at: /tmp/dylanlang/dylanlang_20180808172424_b4838d15-<span class="number">2</span>a3f-<span class="number">45</span>fc-b7a3-<span class="number">3</span>cb30b8a3c27.log</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">Hadoop job information <span class="keyword">for</span> null: number of mappers: <span class="number">0</span>; number of reducers: <span class="number">0</span></span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">24</span>:<span class="number">12</span>,<span class="number">035</span> null map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</span><br><span class="line">Ended Job = job_local276830780_0001</span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">OK</span><br><span class="line"><span class="number">1949</span>    <span class="number">78</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">111</span></span><br><span class="line"><span class="number">1950</span>    -<span class="number">11</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">22</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">0</span></span><br><span class="line">Time taken: <span class="number">6.047</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; from records2 select year, temperature distribute by year</span><br><span class="line">    &gt; ;</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks not specified. Estimated from input <span class="keyword">data</span> size: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">27</span>:<span class="number">18</span>,<span class="number">889</span> WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(<span class="number">62</span>)) - Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">27</span>:<span class="number">19</span>,<span class="number">087</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">27</span>-<span class="number">16</span>_436_7612427717929668210-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">27</span>:<span class="number">19</span>,<span class="number">109</span> WARN  [main] conf.Configuration (Configuration.java:loadProperty(<span class="number">2368</span>)) - file:/tmp/dylanlang/hive_2018-<span class="number">08</span>-<span class="number">08</span>_17-<span class="number">27</span>-<span class="number">16</span>_436_7612427717929668210-<span class="number">1</span>/-local-<span class="number">10003</span>/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">Execution log at: /tmp/dylanlang/dylanlang_20180808172727_31268aee-<span class="number">92</span>ac-<span class="number">4</span>cce-<span class="number">97</span>a0-eb266bb884ac.log</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">Hadoop job information <span class="keyword">for</span> null: number of mappers: <span class="number">0</span>; number of reducers: <span class="number">0</span></span><br><span class="line"><span class="number">2018</span>-<span class="number">08</span>-<span class="number">08</span> <span class="number">17</span>:<span class="number">27</span>:<span class="number">22</span>,<span class="number">531</span> null map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%</span><br><span class="line">Ended Job = job_local1287262186_0001</span><br><span class="line">Execution completed successfully</span><br><span class="line">MapredLocal task succeeded</span><br><span class="line">OK</span><br><span class="line"><span class="number">1949</span>    <span class="number">78</span></span><br><span class="line"><span class="number">1949</span>    <span class="number">111</span></span><br><span class="line"><span class="number">1950</span>    -<span class="number">11</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">22</span></span><br><span class="line"><span class="number">1950</span>    <span class="number">0</span></span><br><span class="line">Time taken: <span class="number">6.497</span> seconds, Fetched: <span class="number">5</span> row(s)</span><br></pre></td></tr></table></figure>
<h3 id="Hive-cluster-by-vs-order-by-vs-sort-by"><a href="#Hive-cluster-by-vs-order-by-vs-sort-by" class="headerlink" title="Hive cluster by vs order by vs sort by"></a><a href="https://stackoverflow.com/questions/13715044/hive-cluster-by-vs-order-by-vs-sort-by" target="_blank" rel="noopener">Hive cluster by vs order by vs sort by</a></h3><blockquote>
<p>A shorter answer: yes, CLUSTER BY guarantees global ordering, provided you’re willing to join the multiple output files yourself.</p>
</blockquote>
<blockquote>
<p>The longer version:</p>
<ul>
<li><code>ORDER BY x</code>: guarantees global ordering, but does this by pushing all data through just one reducer. This is basically unacceptable for large datasets. You end up one sorted file as output.</li>
<li><code>SORT BY x</code>: orders data at each of N reducers, but each reducer can receive overlapping ranges of data. You end up with N or more sorted files with overlapping ranges.</li>
<li><code>DISTRIBUTE BY x</code>: ensures each of N reducers gets non-overlapping ranges of x, but doesn’t sort the output of each reducer. You end up with N or unsorted files with non-overlapping ranges.</li>
<li><code>CLUSTER BY x</code>: ensures each of N reducers gets non-overlapping ranges, then sorts by those ranges at the reducers. This gives you global ordering, and is the same as doing (DISTRIBUTE BY x and SORT BY x). You end up with N or more sorted files with non-overlapping ranges.</li>
</ul>
</blockquote>
<blockquote>
<p>Make sense? So <code>CLUSTER BY</code> is basically the more scalable version of <code>ORDER BY</code>.</p>
</blockquote>
<h3 id="MapReduce脚本"><a href="#MapReduce脚本" class="headerlink" title="MapReduce脚本"></a>MapReduce脚本</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[dylanlang@dylan20 ~/learning/hadoop/hive/scripts]$ vi is_good_quality.py</span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"> </span><br><span class="line">import re</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin</span><br><span class="line">    (year, temp, q) = line.strip().split()</span><br><span class="line">    <span class="keyword">if</span>(temp != <span class="string">"9999"</span> and re.match(<span class="string">"[01459]"</span>, q)):</span><br><span class="line">        print <span class="string">"%s\t%s"</span> % (year, temp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; add file /home/dylanlang/learning/hadoop/hive/scripts/is_good_quality.py;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; from records2 select transform(year, temperature, quality) using <span class="string">'is_good_quality.py'</span> as year, temperature;</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">2018-08-08 18:52:48,653 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_18-52-46_421_3181353316449026664-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span></span><br><span class="line"><span class="string">2018-08-08 18:52:48,675 WARN  [main] conf.Configuration (Configuration.java:loadProperty(2368)) - file:/tmp/dylanlang/hive_2018-08-08_18-52-46_421_3181353316449026664-1/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span></span><br><span class="line"><span class="string">2018-08-08 18:52:48,891 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:&lt;clinit&gt;(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span></span><br><span class="line"><span class="string">Execution log at: /tmp/dylanlang/dylanlang_20180808185252_74b8fae5-bea0-4776-a999-ea54a5cb4563.log</span></span><br><span class="line"><span class="string">Job running in-process (local Hadoop)</span></span><br><span class="line"><span class="string">Hadoop job information for null: number of mappers: 0; number of reducers: 0</span></span><br><span class="line"><span class="string">2018-08-08 18:52:52,445 null map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">Ended Job = job_local70841101_0001 with errors</span></span><br><span class="line"><span class="string">Error during job, obtaining debugging information...</span></span><br><span class="line"><span class="string">Job Tracking URL: http://localhost:8080/</span></span><br><span class="line"><span class="string">Execution failed with exit status: 2</span></span><br><span class="line"><span class="string">Obtaining error information</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Task failed!</span></span><br><span class="line"><span class="string">Task ID:</span></span><br><span class="line"><span class="string">  Stage-1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Logs:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/tmp/dylanlang/hive.log</span></span><br><span class="line"><span class="string">FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</span></span><br></pre></td></tr></table></figure>
<h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE IF EXISTS sales;</span><br><span class="line">CREATE TABLE sales (name STRING, id INT)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;;</span><br><span class="line"></span><br><span class="line">DROP TABLE IF EXISTS things;</span><br><span class="line">CREATE TABLE things (id INT, name STRING)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;;</span><br><span class="line"></span><br><span class="line">LOAD DATA LOCAL INPATH &apos;/home/dylanlang/learning/hadoop/input/hive/joins/sales.txt&apos;</span><br><span class="line">OVERWRITE INTO TABLE sales;</span><br><span class="line"></span><br><span class="line">LOAD DATA LOCAL INPATH &apos;/home/dylanlang/learning/hadoop/input/hive/joins/things.txt&apos;</span><br><span class="line">OVERWRITE INTO TABLE things;</span><br><span class="line"></span><br><span class="line">hive&gt; select * from sales;</span><br><span class="line">OK</span><br><span class="line">Joe     2</span><br><span class="line">Hank    4</span><br><span class="line">Ali     0</span><br><span class="line">Eve     3</span><br><span class="line">Hank    2</span><br><span class="line">Time taken: 0.016 seconds, Fetched: 5 row(s)</span><br><span class="line">hive&gt; select * from things;</span><br><span class="line">OK</span><br><span class="line">2       Tie</span><br><span class="line">4       Coat</span><br><span class="line">3       Hat</span><br><span class="line">1       Scarf</span><br><span class="line">Time taken: 0.022 seconds, Fetched: 4 row(s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; explain</span><br><span class="line">    &gt; select sales.*, things.*</span><br><span class="line">    &gt; from sales join things on (sales.id = things.id);</span><br><span class="line">OK</span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-4 is a root stage</span><br><span class="line">  Stage-3 depends on stages: Stage-4</span><br><span class="line">  Stage-0 is a root stage</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-4</span><br><span class="line">    Map Reduce Local Work</span><br><span class="line">      Alias -&gt; Map Local Tables:</span><br><span class="line">        things</span><br><span class="line">          Fetch Operator</span><br><span class="line">            limit: -1</span><br><span class="line">      Alias -&gt; Map Local Operator Tree:</span><br><span class="line">        things</span><br><span class="line">          TableScan</span><br><span class="line">            alias: things</span><br><span class="line">            Statistics: Num rows: 0 Data size: 29 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">            HashTable Sink Operator</span><br><span class="line">              condition expressions:</span><br><span class="line">                0 &#123;name&#125; &#123;id&#125;</span><br><span class="line">                1 &#123;id&#125; &#123;name&#125;</span><br><span class="line">              keys:</span><br><span class="line">                0 id (type: int)</span><br><span class="line">                1 id (type: int)</span><br><span class="line"></span><br><span class="line">  Stage: Stage-3</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: sales</span><br><span class="line">            Statistics: Num rows: 0 Data size: 35 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">            Map Join Operator</span><br><span class="line">              condition map:</span><br><span class="line">                   Inner Join 0 to 1</span><br><span class="line">              condition expressions:</span><br><span class="line">                0 &#123;name&#125; &#123;id&#125;</span><br><span class="line">                1 &#123;id&#125; &#123;name&#125;</span><br><span class="line">              keys:</span><br><span class="line">                0 id (type: int)</span><br><span class="line">                1 id (type: int)</span><br><span class="line">              outputColumnNames: _col0, _col1, _col4, _col5</span><br><span class="line">              Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">              Select Operator</span><br><span class="line">                expressions: _col0 (type: string), _col1 (type: int), _col4 (type: int), _col5 (type: string)</span><br><span class="line">                outputColumnNames: _col0, _col1, _col2, _col3</span><br><span class="line">                Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">                File Output Operator</span><br><span class="line">                  compressed: false</span><br><span class="line">                  Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">                  table:</span><br><span class="line">                      input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">      Local Work:</span><br><span class="line">        Map Reduce Local Work</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit: -1</span><br><span class="line"></span><br><span class="line">Time taken: 0.142 seconds, Fetched: 60 row(s)</span><br><span class="line">hive&gt; explain extended</span><br><span class="line">    &gt; select sales.*, things.*</span><br><span class="line">    &gt; from sales join things on (sales.id = things.id);</span><br><span class="line">OK</span><br><span class="line">ABSTRACT SYNTAX TREE:</span><br><span class="line"></span><br><span class="line">TOK_QUERY</span><br><span class="line">   TOK_FROM</span><br><span class="line">      TOK_JOIN</span><br><span class="line">         TOK_TABREF</span><br><span class="line">            TOK_TABNAME</span><br><span class="line">               sales</span><br><span class="line">         TOK_TABREF</span><br><span class="line">            TOK_TABNAME</span><br><span class="line">               things</span><br><span class="line">         =</span><br><span class="line">            .</span><br><span class="line">               TOK_TABLE_OR_COL</span><br><span class="line">                  sales</span><br><span class="line">               id</span><br><span class="line">            .</span><br><span class="line">               TOK_TABLE_OR_COL</span><br><span class="line">                  things</span><br><span class="line">               id</span><br><span class="line">   TOK_INSERT</span><br><span class="line">      TOK_DESTINATION</span><br><span class="line">         TOK_DIR</span><br><span class="line">            TOK_TMP_FILE</span><br><span class="line">      TOK_SELECT</span><br><span class="line">         TOK_SELEXPR</span><br><span class="line">            TOK_ALLCOLREF</span><br><span class="line">               TOK_TABNAME</span><br><span class="line">                  sales</span><br><span class="line">         TOK_SELEXPR</span><br><span class="line">            TOK_ALLCOLREF</span><br><span class="line">               TOK_TABNAME</span><br><span class="line">                  things</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-4 is a root stage</span><br><span class="line">  Stage-3 depends on stages: Stage-4</span><br><span class="line">  Stage-0 is a root stage</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-4</span><br><span class="line">    Map Reduce Local Work</span><br><span class="line">      Alias -&gt; Map Local Tables:</span><br><span class="line">        things</span><br><span class="line">          Fetch Operator</span><br><span class="line">            limit: -1</span><br><span class="line">      Alias -&gt; Map Local Operator Tree:</span><br><span class="line">        things</span><br><span class="line">          TableScan</span><br><span class="line">            alias: things</span><br><span class="line">            Statistics: Num rows: 0 Data size: 29 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">            GatherStats: false</span><br><span class="line">            HashTable Sink Operator</span><br><span class="line">              condition expressions:</span><br><span class="line">                0 &#123;name&#125; &#123;id&#125;</span><br><span class="line">                1 &#123;id&#125; &#123;name&#125;</span><br><span class="line">              keys:</span><br><span class="line">                0 id (type: int)</span><br><span class="line">                1 id (type: int)</span><br><span class="line">              Position of Big Table: 0</span><br><span class="line"></span><br><span class="line">  Stage: Stage-3</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            alias: sales</span><br><span class="line">            Statistics: Num rows: 0 Data size: 35 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">            GatherStats: false</span><br><span class="line">            Map Join Operator</span><br><span class="line">              condition map:</span><br><span class="line">                   Inner Join 0 to 1</span><br><span class="line">              condition expressions:</span><br><span class="line">                0 &#123;name&#125; &#123;id&#125;</span><br><span class="line">                1 &#123;id&#125; &#123;name&#125;</span><br><span class="line">              keys:</span><br><span class="line">                0 id (type: int)</span><br><span class="line">                1 id (type: int)</span><br><span class="line">              outputColumnNames: _col0, _col1, _col4, _col5</span><br><span class="line">              Position of Big Table: 0</span><br><span class="line">              Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">              Select Operator</span><br><span class="line">                expressions: _col0 (type: string), _col1 (type: int), _col4 (type: int), _col5 (type: string)</span><br><span class="line">                outputColumnNames: _col0, _col1, _col2, _col3</span><br><span class="line">                Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">                File Output Operator</span><br><span class="line">                  compressed: false</span><br><span class="line">                  GlobalTableId: 0</span><br><span class="line">                  directory: file:/tmp/dylanlang/hive_2018-08-08_19-45-20_665_651617886913666306-1/-ext-10001</span><br><span class="line">                  NumFilesPerFileSink: 1</span><br><span class="line">                  Statistics: Num rows: 0 Data size: 38 Basic stats: PARTIAL Column stats: NONE</span><br><span class="line">                  Stats Publishing Key Prefix: file:/tmp/dylanlang/hive_2018-08-08_19-45-20_665_651617886913666306-1/-ext-10001/</span><br><span class="line">                  table:</span><br><span class="line">                      input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                      properties:</span><br><span class="line">                        columns _col0,_col1,_col2,_col3</span><br><span class="line">                        columns.types string:int:int:string</span><br><span class="line">                        escape.delim \</span><br><span class="line">                        hive.serialization.extend.nesting.levels true</span><br><span class="line">                        serialization.format 1</span><br><span class="line">                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                  TotalFiles: 1</span><br><span class="line">                  GatherStats: false</span><br><span class="line">                  MultiFileSpray: false</span><br><span class="line">      Local Work:</span><br><span class="line">        Map Reduce Local Work</span><br><span class="line">      Path -&gt; Alias:</span><br><span class="line">        hdfs://localhost:9000/user/hive/warehouse/sales [sales]</span><br><span class="line">      Path -&gt; Partition:</span><br><span class="line">        hdfs://localhost:9000/user/hive/warehouse/sales</span><br><span class="line">          Partition</span><br><span class="line">            base file name: sales</span><br><span class="line">            input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">            properties:</span><br><span class="line">              COLUMN_STATS_ACCURATE true</span><br><span class="line">              bucket_count -1</span><br><span class="line">              columns name,id</span><br><span class="line">              columns.comments</span><br><span class="line">              columns.types string:int</span><br><span class="line">              field.delim</span><br><span class="line">              file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              location hdfs://localhost:9000/user/hive/warehouse/sales</span><br><span class="line">              name default.sales</span><br><span class="line">              numFiles 1</span><br><span class="line">              numRows 0</span><br><span class="line">              rawDataSize 0</span><br><span class="line">              serialization.ddl struct sales &#123; string name, i32 id&#125;</span><br><span class="line">              serialization.format</span><br><span class="line">              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              totalSize 35</span><br><span class="line">              transient_lastDdlTime 1533728232</span><br><span class="line">            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">              input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              properties:</span><br><span class="line">                COLUMN_STATS_ACCURATE true</span><br><span class="line">                bucket_count -1</span><br><span class="line">                columns name,id</span><br><span class="line">                columns.comments</span><br><span class="line">                columns.types string:int</span><br><span class="line">                field.delim</span><br><span class="line">                file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                location hdfs://localhost:9000/user/hive/warehouse/sales</span><br><span class="line">                name default.sales</span><br><span class="line">                numFiles 1</span><br><span class="line">                numRows 0</span><br><span class="line">                rawDataSize 0</span><br><span class="line">                serialization.ddl struct sales &#123; string name, i32 id&#125;</span><br><span class="line">                serialization.format</span><br><span class="line">                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                totalSize 35</span><br><span class="line">                transient_lastDdlTime 1533728232</span><br><span class="line">              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              name: default.sales</span><br><span class="line">            name: default.sales</span><br><span class="line">        hdfs://localhost:9000/user/hive/warehouse/things</span><br><span class="line">          Partition</span><br><span class="line">            base file name: things</span><br><span class="line">            input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">            properties:</span><br><span class="line">              COLUMN_STATS_ACCURATE true</span><br><span class="line">              bucket_count -1</span><br><span class="line">              columns id,name</span><br><span class="line">              columns.comments</span><br><span class="line">              columns.types int:string</span><br><span class="line">              field.delim</span><br><span class="line">              file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              location hdfs://localhost:9000/user/hive/warehouse/things</span><br><span class="line">              name default.things</span><br><span class="line">              numFiles 1</span><br><span class="line">              numRows 0</span><br><span class="line">              rawDataSize 0</span><br><span class="line">              serialization.ddl struct things &#123; i32 id, string name&#125;</span><br><span class="line">              serialization.format</span><br><span class="line">              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              totalSize 29</span><br><span class="line">              transient_lastDdlTime 1533728236</span><br><span class="line">            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">              input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">              properties:</span><br><span class="line">                COLUMN_STATS_ACCURATE true</span><br><span class="line">                bucket_count -1</span><br><span class="line">                columns id,name</span><br><span class="line">                columns.comments</span><br><span class="line">                columns.types int:string</span><br><span class="line">                field.delim</span><br><span class="line">                file.inputformat org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                location hdfs://localhost:9000/user/hive/warehouse/things</span><br><span class="line">                name default.things</span><br><span class="line">                numFiles 1</span><br><span class="line">                numRows 0</span><br><span class="line">                rawDataSize 0</span><br><span class="line">                serialization.ddl struct things &#123; i32 id, string name&#125;</span><br><span class="line">                serialization.format</span><br><span class="line">                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">                totalSize 29</span><br><span class="line">                transient_lastDdlTime 1533728236</span><br><span class="line">              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">              name: default.things</span><br><span class="line">            name: default.things</span><br><span class="line">      Truncated Path -&gt; Alias:</span><br><span class="line">        /sales [sales]</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit: -1</span><br><span class="line"></span><br><span class="line">Time taken: 0.081 seconds, Fetched: 218 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;select station, year, avg(max_temperature) </span><br><span class="line">     from ( </span><br><span class="line">     select station, year, max(temperature) as max_temperature</span><br><span class="line">     from records2</span><br><span class="line">     where temperature != 9999 and quality in (0,1,4,5,9)</span><br><span class="line">     group by station, year</span><br><span class="line">     ) mt</span><br><span class="line">     group by station, year;</span><br></pre></td></tr></table></figure>
<h2 id="Hive与传统数据库比较"><a href="#Hive与传统数据库比较" class="headerlink" title="Hive与传统数据库比较"></a>Hive与传统数据库比较</h2><p>Hive处理的数据是大数据，在保存表数据时不对数据进行校验，而是在读数据时校验，不符合格式的数据设置为NULL；</p>
<p>读时模式的优点是，加载数据库快。</p>
<p>传统的数据库如mysql、oracle是写时模式，不符合格式的数据写不进去。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>create table if not exists employee (eid int ,name String ,salary int, destination String) comment ‘Employee details’ row format delimited fields terminated by ‘\t’ lines terminated by ‘\n’ stored as textfile;</p>
<p>hive&gt;<br>load data local inpath ‘/home/dylanlang/learning/hadoop/hive/samples/sample.txt’ overwrite into table records;</p>
<p>create table records (year string, temperature int, quality int) row format delimited fields terminated by ‘\t’;load data local inpath ‘/home/dylanlang/learning/hadoop/input/ncdc/micro-tab/sample.txt’ overwrite into table records;</p>
<p>hadoop fs -mkdir /tmp &amp;&amp;  hadoop fs -mkdir -p  /user/hive/warehouse &amp;&amp;  hadoop fs -chmod g+w /tmp &amp;&amp;  hadoop fs -chmod g+w /user/hive/warehouse</p>
<h3 id="InvalidObjectException-message-Role-admin-already-exists"><a href="#InvalidObjectException-message-Role-admin-already-exists" class="headerlink" title="InvalidObjectException(message:Role admin already exists.)"></a>InvalidObjectException(message:Role admin already exists.)</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.HiveMetaStore: admin role already exists</span><br><span class="line">InvalidObjectException(message:Role admin already exists.)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:<span class="number">3020</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:<span class="number">108</span>)</span><br><span class="line">        at com.sun.proxy.<span class="variable">$Proxy6</span>.addRole(Unknown Source)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.createDefaultRoles(HiveMetaStore.java:<span class="number">544</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.init(HiveMetaStore.java:<span class="number">398</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.&lt;init&gt;(HiveMetaStore.java:<span class="number">356</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:<span class="number">54</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:<span class="number">59</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:<span class="number">4944</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:<span class="number">171</span>)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">423</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1410</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:<span class="number">62</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">72</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:<span class="number">2453</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:<span class="number">2465</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:<span class="number">681</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:<span class="number">625</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">212</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: INFO metastore.HiveMetaStore: Added admin role <span class="keyword">in</span> metastore</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Open transaction: count = <span class="number">1</span>, isActive = true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:<span class="number">3017</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Open transaction: count = <span class="number">2</span>, isActive = true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:<span class="number">3296</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Commit transaction: count = <span class="number">1</span>, isactive true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.getMRole(ObjectStore.java:<span class="number">3302</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Rollback transaction, isActive: true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:<span class="number">3030</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.HiveMetaStore: public role already exists</span><br><span class="line">InvalidObjectException(message:Role public already exists.)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.ObjectStore.addRole(ObjectStore.java:<span class="number">3020</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:<span class="number">108</span>)</span><br><span class="line">        at com.sun.proxy.<span class="variable">$Proxy6</span>.addRole(Unknown Source)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.createDefaultRoles(HiveMetaStore.java:<span class="number">553</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.init(HiveMetaStore.java:<span class="number">398</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.&lt;init&gt;(HiveMetaStore.java:<span class="number">356</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:<span class="number">54</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:<span class="number">59</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:<span class="number">4944</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:<span class="number">171</span>)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">423</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1410</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:<span class="number">62</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">72</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:<span class="number">2453</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:<span class="number">2465</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:<span class="number">681</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:<span class="number">625</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">212</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: INFO metastore.HiveMetaStore: Added public role <span class="keyword">in</span> metastore</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Open transaction: count = <span class="number">1</span>, isActive = true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:<span class="number">3681</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Open transaction: count = <span class="number">2</span>, isActive = true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.listPrincipalGlobalGrants(ObjectStore.java:<span class="number">4109</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Commit transaction: count = <span class="number">1</span>, isactive true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.listPrincipalGlobalGrants(ObjectStore.java:<span class="number">4119</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.ObjectStore: Rollback transaction, isActive: true at:</span><br><span class="line">        org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:<span class="number">3880</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG metastore.HiveMetaStore: Failed <span class="keyword">while</span> granting global privs to admin</span><br><span class="line">InvalidObjectException(message:All is already granted by admin)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.ObjectStore.grantPrivileges(ObjectStore.java:<span class="number">3713</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:<span class="number">108</span>)</span><br><span class="line">        at com.sun.proxy.<span class="variable">$Proxy6</span>.grantPrivileges(Unknown Source)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.createDefaultRoles(HiveMetaStore.java:<span class="number">567</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.init(HiveMetaStore.java:<span class="number">398</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore<span class="variable">$HMSHandler</span>.&lt;init&gt;(HiveMetaStore.java:<span class="number">356</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:<span class="number">54</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:<span class="number">59</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:<span class="number">4944</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:<span class="number">171</span>)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">423</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1410</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:<span class="number">62</span>)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">72</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:<span class="number">2453</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:<span class="number">2465</span>)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">340</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:<span class="number">681</span>)</span><br><span class="line">        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:<span class="number">625</span>)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">212</span>)</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: INFO metastore.HiveMetaStore: No user is added <span class="keyword">in</span> admin role, since config is empty</span><br><span class="line"><span class="number">18</span>/<span class="number">08</span>/<span class="number">08</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">22</span> [main]: DEBUG security.UserGroupInformation: hadoop login</span><br></pre></td></tr></table></figure>
<p>rm derby.log ; rm -r metastore_db/ ; hive -hiveconf hive.root.logger=DEBUG,console</p>
<p><a href="https://www.cnblogs.com/raphael5200/p/5177457.html" target="_blank" rel="noopener">https://www.cnblogs.com/raphael5200/p/5177457.html</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
            <a href="/tags/Hive/" rel="tag"># Hive</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/05/Haddop/关于Pig/" rel="next" title="关于Pig">
                <i class="fa fa-chevron-left"></i> 关于Pig
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/08/Haddop/关于Spark/" rel="prev" title="关于Spark">
                关于Spark <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2018/08/07/Haddop/关于Hive/" data-title="关于Hive" data-url="http://yoursite.com/2018/08/07/Haddop/关于Hive/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="Dylan Lang">
            
              <p class="site-author-name" itemprop="name">Dylan Lang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">513</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">120</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yourname" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yourname@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装Hive"><span class="nav-number">1.</span> <span class="nav-text">安装Hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动Hive"><span class="nav-number">2.</span> <span class="nav-text">启动Hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#示例"><span class="nav-number">3.</span> <span class="nav-text">示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行hive"><span class="nav-number">4.</span> <span class="nav-text">运行hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分区和桶"><span class="nav-number">5.</span> <span class="nav-text">分区和桶</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#分区"><span class="nav-number">5.1.</span> <span class="nav-text">分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#桶"><span class="nav-number">5.2.</span> <span class="nav-text">桶</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查询数据"><span class="nav-number">6.</span> <span class="nav-text">查询数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#排序和聚集"><span class="nav-number">6.1.</span> <span class="nav-text">排序和聚集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-cluster-by-vs-order-by-vs-sort-by"><span class="nav-number">6.2.</span> <span class="nav-text">Hive cluster by vs order by vs sort by</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce脚本"><span class="nav-number">6.3.</span> <span class="nav-text">MapReduce脚本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连接"><span class="nav-number">6.4.</span> <span class="nav-text">连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#子查询"><span class="nav-number">6.5.</span> <span class="nav-text">子查询</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive与传统数据库比较"><span class="nav-number">7.</span> <span class="nav-text">Hive与传统数据库比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">8.</span> <span class="nav-text">参考文献</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#InvalidObjectException-message-Role-admin-already-exists"><span class="nav-number">8.1.</span> <span class="nav-text">InvalidObjectException(message:Role admin already exists.)</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dylan Lang</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
